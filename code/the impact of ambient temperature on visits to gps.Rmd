---
title: "Impact of Ambient Temperature on Visits to General Practitioners"
author: "Raphael Kroes"
date: "2023-12-02"
output: html_document
---

This is the main Markdown file for the data analysis of 'Impact of Ambient Temperature on Visits to General Practitioners' by Raphael Kroes.
The original data cannot be provided publicly because of data protection reasons. However, an algorithm to create a fake dataset is provided, which can be used to test the code.
```{r}
library(devtools)
library(readxl)
library(lubridate)
library(dplyr)
library(parallel)
library(lightgbm)
library(VGAM)
```
```{r}


#read file with functions
source("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/code/functions_mt.R")

#read auxiliary data files
ListeKrankenkassen<- read.csv("https://raw.githubusercontent.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/main/other%20data/ListeKrankenkassen_up.csv")
classification.matrix<- read.csv("https://raw.githubusercontent.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/main/other%20data/classification.csv")
icd10_blocks<- read.csv("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/other%20data/icd10_blocks.csv")
holidays<- read.csv("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/other%20data/numeric_holidays.csv")

fake.data<- TRUE
if(fake.data){
  source_url("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/code/fakedgp_mt.R")
}else{
  old.wd<- getwd()
  setwd("N:/StudentischeHilfskraefte/_Kroes (Christoph)/Routinedaten/01_Husten/R/DB")
  names.vec<- c("Diag3","Stamm3","Konsul3")
  
  for (i in seq(1,length(names.vec))){
    file.name<- paste0("DB_",names.vec[i],"_v03",".csv")
  
    im.file<- read.csv(file = file.name, header = TRUE, sep = ";")
  
    assign(names.vec[i],im.file)
  
  }
  # remove duplicate file and unnecessary name
  rm(file.name,im.file)
  
  setwd(old.wd)
}

#date range
date.range<- range(Diag3$TG_DateNum)

#location data
location_information<- read.csv("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/other%20data/location%20information.csv", header = TRUE, encoding = "Latin-1")
location.name<- location_information$location.name

#weather data
for(i in seq_along(location.name)){
  url_string<- paste0("https://raw.githubusercontent.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/main/weather%20data/wetter%20",location.name[i],".csv")
  im<- read.csv(url_string)
  colnames(im)<- c("time", "temperature_celsius", "relative_humidity", "dew_point", "apparent_temperature_celsius", "precipitation", "rain", "snow_fall", "snow_depth", "surface_pressure")

  #unit transformations
  im$TG_DateNum<- date2TG_DateNum(im$time)
  im<- im|>
    filter(TG_DateNum>=date.range[1]-21 & TG_DateNum<=date.range[2])
  im$temperature_kelvin<- im$temperature_celsius +273.16
  
  weatherdata.transformation(im,sel.quantile = .95, loc = location.name[i], dr = date.range)
  #assign(paste0("wetter_",location.name[i]),im)
}



#daylight data
for(i in seq_along(location.name)){
  url_string<- paste0("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/daylight%20hours%20data/daylight_",location.name[i],".csv")
  im<- read.csv(url_string, header = TRUE)
  
  #unit transformations
  #im$TG_DateNum<- date2TG_DateNum(im$time)
  im<- im|>
    filter(TG_DateNum>=date.range[1] & TG_DateNum<=date.range[2])
  assign(paste0("daylight_",location.name[i]),im)
}

#Covid-19 data
covid.data<- read.csv("https://github.com/rapkroes/impact-of-ambient-temperature-on-visits-to-general-practitioners/raw/main/other%20data/COVID-19-Faelle_7-Tage-Inzidenz_Landkreise.csv")
covid.data<- covid.data|>
  filter(Landkreis_id %in% location_information$landkreis_id)
covid.data$TG_DateNum<- date2TG_DateNum(covid.data$Meldedatum)





```
We must check Diag's icd10 column: Since the icd10 field is a text field in the GP's software, the data might contain typing errors or atypical notation of diseases. This function returns a vector that filters out whose entries are =1 if they are 'suspicious' and 0 otherwise. An entry is considered suspicious if it does not have a length of 4, 6, or 7 characters. If it has 4, 6, or 7 characters it is suspicious if it does not follow either of the patterns "capital letter, two numbers, capital letter" or "capital letter, two numbers, fullstop, one or two numbers, capital letter".
```{r}
View(Diag3[as.logical(suspicious.Diag.entries(Diag3$icd10)),])
```

Merging and transformation process, using Diag as baseline:
1. Filter out chronic diseases and add them as patient specific variables
2. Merge Stamm data, create new gender dummy, add dummy for private or public health insurance provider, add county (Landkreis; for convenience)
3. Merge Konsul data (and remove duplicate columns)
4. Create time variables from the date
5. Merge Covid-19 incidence values, also add dummy variable for incidence larger than zero
6. Create risk factors variables
```{r}
### acute and chronic diseases, last visit
chronic.sel<- grepl("DD",Diag3$DiagTyp)
chronic.df<- as.data.frame(cbind(Diag3$uniPatID,Diag3$icd10)[chronic.sel,])|>
  distinct()
colnames(chronic.df)<- c("uniPatID", "diag_category")
chronic.df$diag_category<- icd10.to.class(chronic.df$diag_category)
full.df_1<- add.chronic(Diag3[!chronic.sel,], chronic.df)
full.df_1$diag_class<- icd10.to.class(full.df_1$icd10)
full.df_1.1<- add.last.visit(full.df_1, no.splits = 50, no.workers = 2)

### stamm data
full.df_1.2<- add.stamm.new.par(full.df_1.1,Stamm3,no.splits = 50, no.workers = 2)
# gender variable
gender.selector<- full.df_1.2$Weibl==1 | full.df_1.2$Maennl==1 | full.df_1.2$stamm.is.there==0
full.df_1.2$female<- full.df_1.2$Weibl
full.df_1.3<- full.df_1.2[gender.selector,]|>
  select(-Weibl,-Maennl,-Transgen,-Divers,-Geschlundef)
#add PKV (private health insurance) dummy
full.df_1.3$PKV<- IK2PKV(full.df_1.3$IK)
#add Landkreis_id
full.df_1.3$landkreis<- praxisID2location(full.df_1.3$PraxisID)

### konsul
full.df_2<- add.konsul(full.df_1.3, Konsul3, no.splits = 50, no.workers = 2)
col.selector<- !duplicated(colnames(full.df_2))
full.df_2.2<- full.df_2[,col.selector]

### time
full.df_3<- full.df_2.2
full.df_3$dow<- as.factor(TG_DateNum2dow(full.df_3$TG_DateNum))
full.df_3<- cbind(full.df_3,TG_DateNum2holiday(full.df_3$TG_DateNum))
full.df_3$week<- as.factor(TG_DateNum2week(full.df_3$TG_DateNum))
full.df_3$week_of_month<- as.factor(TG_DateNum2week.of.month(full.df_3$TG_DateNum))
full.df_3$month<- as.factor(TG_DateNum2month(full.df_3$TG_DateNum))
full.df_3$year<- as.factor(TG_DateNum2year(full.df_3$TG_DateNum))
full.df_3$age<- TG_DateNum2year(full.df_3$TG_DateNum)-full.df_3$Geburtsjahr

### covid-19
full.df_4<- full.df_3
full.df_4$Landkreis_id<- praxis_id2landkreis_id(full.df_4$PraxisID)
full.df_4<- full.df_4|>
  arrange(Landkreis_id,TG_DateNum)
full.df_4.2<- add.covid(full.df_4,covid.data,2)
full.df_4.2$covid_positive_incidence<- full.df_4.2$covid_7_day_incidence>0

### risk factors
full.df_5<- full.df_4.2
full.df_5$smoking<- risk.factor.merger(full.df_5$TG_A_Rauchen,full.df_5$TG_RF_Rauchen)
full.df_5$alcohol<- risk.factor.merger(full.df_5$TG_A_Alkohol,full.df_5$TG_RF_Alkohol)
full.df_5$sport<- risk.factor.merger(full.df_5$TG_A_Sport,full.df_5$TG_RF_Sport)

### add weather variables
full.df_6<- full.df_5
full.df_6<- add.weather(full.df_6,2)

###add daylight data
full.df_7<- full.df_6
full.df_7<- add.daylight(full.df_6,2)|>
  arrange(TG_DateNum)
```
Research Question 1:
```{r}

```


```{r}
###estimate age quantiles
##tune lambda
tuning.wrapper<- function(lambda_value, alpha_value, lc_1, lc_2){
  out<- list()
  out$Score<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = alpha_value, lambda = lambda_value, lc.rho = c(lc_1, lc_2), max.iter = 75)$loss_new
}

tuning.wrapper_2<- function(params){
  lambda_value<- 1/(1+exp(params[1]))
  alpha_value<- 1/(1+exp(params[2]))
  lc_1<- 5/(1+exp(params[3]))
  lc_2<- 5/(1+exp(params[4]))
  out<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = alpha_value, lambda = lambda_value, lc.rho = c(lc_1, lc_2), max.iter = 75)$loss_new
}
tic()
tuning_results<- optim(par = rep(log(4),4), fn = tuning.wrapper_2, method = "Nelder-Mead",
                       control = list(maxit = 20))
toc()#925 sec
tic()
tuning_results<- optim(par = rep(log(4),4), fn = tuning.wrapper_2, method = "SANN",
                       control = list(maxit = 20))
toc()

tic()
age.6.1000<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = .1, lambda = .5, tol = 1e-6, max.iter = 1000, lc.rho = 2)
toc()
tic()
age.6.75<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = .1, lambda = .5, tol = 1e-6, max.iter = 75, lc.rho = 2)
toc()
###########################here
tic()
age.6.75<- elastic.net_speed(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = .1, lambda = 10, tol = 1e-6, max.iter = 50, lc.rho = 100)
toc()

its<- seq(10,100, by=20)
losses<- numeric(length(its))
for(i in seq_along(its)){
  losses[i]<- elastic.net_speed(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = .1, lambda = 10, tol = 1e-6, max.iter = its[i], lc.rho = 100)$loss_new
}
plot(losses~its)


tic()
age.6.75<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$age, spline.pos = 1, spline.knots = 4, sel.loss.function = "quantile", sel.quantile = 0.5, alpha = .1, lambda = .5, tol = 1e-6, max.iter = 75, lc.rho = c(2.9,0.0075))
toc()


tic()
attempt.p.6.1000<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .5, tol = 1e-6, max.iter = 1000)
toc()
tic()
elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .5, tol = 1e-6, max.iter = 100)
toc()
tic()
elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .5, tol = 1e-4, max.iter = 100)
toc()


tic()
attempt.p.4.75<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .2, tol = 1e-4, max.iter = 75)
toc()
tic()
attempt.p.5.75<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .1, tol = 1e-5, max.iter = 75)
toc()
tic()
attempt.p.6.75<- elastic.net(inputdf = rhs_Thom_q1, y= full.df_7$female, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .1, tol = 1e-6, max.iter = 75)
toc()

tuning.wrapper(0.5,0.1,1,1,0.0001)
for(i in 1:11){
  print(i)
  tuning.wrapper(seq(0,1,0.1)[i],0.1,1,1,0.0001)
}
library(tictoc)
library(ParBayesianOptimization)
tic()
trial_bo<- bayesOpt(FUN = tuning.wrapper,
                    bounds = list(lambda_value = c(0,1),
                                  alpha_value = c(0,0.5),
                                  lc_1 = c(0,5),
                                  lc_2 = c(0,5)),
                    initPoints = 5,
                    errorHandling = "continue", plotProgress = TRUE, verbose = 2)
toc()
```
```{r}
# plot effect of TDI
tdi.effect<- function(x,beta,cuts){
  params<- as.vector(beta[grepl("thoms_discomfort_index",colnames(beta))])
  names(params)<- colnames(beta)[grepl("thoms_discomfort_index",colnames(beta))]
  for(i in seq_along(params)){
    varname<- substr(names(params)[i],nchar(names(params)[i])-2,nchar(names(params)[i]))
    assign(varname,params[i])
  }
  out<- numeric(length(x))
  cuts_abridged<- cuts[2:(length(cuts)-1)]
  for(i in seq_along(out)){
    if(x[i]<min(cuts_abridged)){
      out[i]<- a_1*x[i]+b_1
    }else if(x[i]>max(cuts_abridged)){
      no<- length(cuts)-1
      out[i]<- get(paste0("a_",no))*x[i]+get(paste0("b_",no))
    }else{
      no<- 1+sum(x[i]>=cuts_abridged)
      out[i]<- get(paste0("a_",no))*x[i]^3+get(paste0("b_",no))*x[i]^2+get(paste0("c_",no))*x[i]+get(paste0("d_",no))
    }
  }
  return(out)
}
grid<- seq(-3.2,2.1, length.out=1000)
effect_1<- tdi.effect(grid, attempt.p.4.75$beta,attempt.p.4.75$cuts_1)
effect_2<- tdi.effect(grid, attempt.p.5.75$beta,attempt.p.4.75$cuts_1)
effect_3<- tdi.effect(grid, attempt.p.6.75$beta,attempt.p.4.75$cuts_1)
plot(effect_1~grid, type="l", ylim= c(-31,5))
plot(effect_1~grid, type="l", ylim= c(-31,5))+
  abline(v=attempt.p.4.75$cuts_1)
plot(effect_2~grid, type="l", ylim= c(-31,5))
plot(effect_2~grid, type="l", ylim= c(-31,5))+
  abline(v=attempt.p.4.75$cuts_1)
plot(effect_3~grid, type="l", ylim= c(-31,5))
plot(effect_3~grid, type="l", ylim= c(-31,5))+
  abline(v=attempt.p.4.75$cuts_1)
t(rbind(attempt.p.4.75$beta,attempt.p.5.75$beta,attempt.p.6.75$beta))

#effect_4<- tdi.effect(grid, age.6.1000$beta,age_1$cuts_1)
effect_5<- tdi.effect(grid, age.6.75$beta,age_1$cuts_1)
#plot(effect_4~grid, type="l")
plot(effect_5~grid, type="l")
plot(effect_5~grid, type="l")+
  abline(v=attempt.p.4.75$cuts_1)
```






```{r}
#simulate if it works

set.seed(561351)
param.sim_1<- rt(ncol(rhs_Thom_q1),8)
var.sim_1<- as.vector(round(1/(1+exp(-1*as.matrix(rhs_Thom_q1)%*%param.sim_1+rt(nrow(rhs_Thom_q1),9)))))
names(param.sim_1)<- colnames(rhs_Thom_q1)

res.sim_1<- elastic.net(rhs_Thom_q1,var.sim_1, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .1, tol = 1e-6, max.iter = 75)

param.sim_1
res.sim_1$beta

n_mc<- 50
bootstrap.params<- matrix(0,nrow = n_mc,ncol = 49)
for(i in 1:n_mc){
  selector<- sample(1:nrow(rhs_Thom_q1),nrow(rhs_Thom_q1), replace = TRUE)
  bootstrap.sample<- rhs_Thom_q1[selector,]
  bootstrap.params[i,]<- elastic.net(bootstrap.sample,var.sim_1[selector], spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .1, tol = 1e-6, max.iter = 75)$beta
}
colnames(bootstrap.params)<- colnames(res.sim_1$beta)

min.vec<- apply(bootstrap.params,2,min)[1:33]
max.vec<- apply(bootstrap.params,2,max)[1:33]
base<- c(param.sim_1[2:33],0)
found.within<- base>=min.vec & base<=max.vec
cbind(min.vec,max.vec,base,found.within)


####################sim 2####################################
set.seed(561351)
param.sim_2<- rt(ncol(rhs_Thom_q1),8)
ict<-rt(1,8)
var.sim_2<- as.vector(round(1/(1+exp(-1*as.matrix(rhs_Thom_q1)%*%param.sim_1+ict+rnorm(nrow(rhs_Thom_q1))))))
names(param.sim_1)<- colnames(rhs_Thom_q1)

res.sim_2<- elastic.net(rhs_Thom_q1,var.sim_1, spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = .1, tol = 1e-6, max.iter = 75)

param.sim_2
res.sim_2$beta

n_mc<- 50
bootstrap.params<- matrix(0,nrow = n_mc,ncol = 49)
sim.cluster<- makeCluster(3)
clusterExport(sim.cluster, varlist = c("elastic.net","rhs_Thom_q1","var.sim_2"))
bootstrap.params_2<- parLapply(sim.cluster,1:n_mc,fun = function(k){
  set.seed(k)
  selector<- sample(1:nrow(rhs_Thom_q1),nrow(rhs_Thom_q1), replace = TRUE)
  bootstrap.sample<- rhs_Thom_q1[selector,]
  out<- elastic.net(bootstrap.sample,var.sim_2[selector], spline.pos = 1, spline.knots = 4, sel.loss.function = "proportion", alpha = .1, lambda = 0, tol = 1e-6, max.iter = 75)$beta
  return(out)
})
b.params_2<- do.call(rbind, bootstrap.params_2)


min.vec<- apply(b.params_2,2,min)[1:33]
max.vec<- apply(b.params_2,2,max)[1:33]
median.vec<- apply(b.params_2,2,median)[1:33]
base<- param.sim_2[2:34]
found.within<- base>=min.vec & base<=max.vec
cbind(min.vec,max.vec,base,median.vec,found.within)

```


